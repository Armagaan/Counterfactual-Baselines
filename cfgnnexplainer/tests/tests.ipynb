{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the datset\n",
    "DATASET=\"bashapes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == \"bashapes\":\n",
    "    path_log = \"../outputs/bashapes/1653496990/log.txt\"\n",
    "    path_cfs = \"../results/syn1/SGD/syn1_cf_examples_lr0.01_beta0.5_mom0.9_epochs500\"\n",
    "    path_predictions = \"../outputs/bashapes/1653496990/predictions.pkl\"\n",
    "    path_eval_set = \"../data/Eval-sets/eval-set-bashapes.pkl\"\n",
    "\n",
    "elif DATASET == \"treecycles\":\n",
    "    path_log = \"../outputs/treecycles/1653492558/log.txt\"\n",
    "    path_cfs = \"../results/syn4/SGD/syn4_cf_examples_lr0.1_beta0.5_mom0.0_epochs500\"\n",
    "    path_predictions = \"../results/syn4/SGD/predictions.pkl\"\n",
    "    path_eval_set = \"../data/Eval-sets/eval-set-treecycles.pkl\"\n",
    "\n",
    "elif DATASET == \"treegrids\":\n",
    "    path_log = \"../outputs/treegrids/1653500919/log.txt\"\n",
    "    path_cfs = \"../results/syn5/SGD/syn5_cf_examples_lr0.1_beta0.5_mom0.0_epochs500\"\n",
    "    path_predictions = \"../results/syn5/SGD/predictions.pkl\"\n",
    "    path_eval_set = \"../data/Eval-sets/eval-set-treegrids.pkl\"\n",
    "\n",
    "else:\n",
    "    print(\"Invalid dataset!\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_log, \"r\") as file:\n",
    "    log = file.readlines()\n",
    "\n",
    "with open(path_cfs, \"rb\") as file:\n",
    "    cfs = pickle.load(file)\n",
    "\n",
    "with open(path_predictions, \"rb\") as file:\n",
    "    predictions = pickle.load(file)\n",
    "\n",
    "with open(path_eval_set, \"rb\") as file:\n",
    "    eval_set = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Format of lists within cfs:\n",
    "\n",
    "If cf is not found for a node: []\n",
    "\n",
    "If cf is found for a node: [\n",
    "    0. 'node_idx', # index in the full graph\n",
    "    1. 'new_idx', # index in the extracted subgraph\n",
    "    2. 'cf_adj', # mask over the subgraph adjacency\n",
    "    3. 'sub_adj', # subgraph adjacency\n",
    "    4. 'y_pred_orig', # target node's prediction on the full graph prior to perturbation\n",
    "    5. 'y_pred_new', # target node's prediction on the non-binary subgraph post perturbation\n",
    "    6. 'y_pred_new_actual', # target node's prediction on the binary subgraph post perturbation\n",
    "    7. 'sub_labels[new_idx]', # target node's predicted label in the subgraph\n",
    "    8. 'sub_adj.shape[0]', # #nodes in the subgraph\n",
    "    9. 'loss_total', # combination of 11 and 12.\n",
    "    10. 'loss_pred', # loss\n",
    "    11. 'loss_graph_dist' # #edge-deletions\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == \"bashapes\":\n",
    "    NUMBER_OF_LABELS = 4\n",
    "else:\n",
    "    NUMBER_OF_LABELS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTIONS = {node:int(prediction) for node, prediction in enumerate(predictions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NODES_PER_PREDICTED_LABEL = defaultdict(int)\n",
    "for node in PREDICTIONS:\n",
    "    label = PREDICTIONS[node]\n",
    "    NODES_PER_PREDICTED_LABEL[f\"label-{label}\"] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'label-0': 300, 'label-1': 166, 'label-2': 144, 'label-3': 90})\n"
     ]
    }
   ],
   "source": [
    "print(NODES_PER_PREDICTED_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTIONS_EVAL_SET = {node:label for node, label in PREDICTIONS.items() if node in eval_set}\n",
    "\n",
    "NODES_PER_PREDICTED_LABEL_IN_EVAL_SET = defaultdict(int)\n",
    "for node in PREDICTIONS_EVAL_SET:\n",
    "    label = PREDICTIONS_EVAL_SET[node]\n",
    "    NODES_PER_PREDICTED_LABEL_IN_EVAL_SET[f\"label-{label}\"] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'label-1': 29, 'label-3': 17, 'label-2': 30})\n"
     ]
    }
   ],
   "source": [
    "print(NODES_PER_PREDICTED_LABEL_IN_EVAL_SET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-label explanation size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have a dictionary for each label\n",
    "per_label_explanation_size = defaultdict(list)\n",
    "nodes_per_prediction = defaultdict(int)\n",
    "\n",
    "# iterate over the cfs\n",
    "for cf in cfs:\n",
    "    # if: cf is []: cf wasn't found, hence skip to next iteration\n",
    "    if cf == []:\n",
    "        continue\n",
    "    # get cf[-1][5] initial prediction over that node in the subgraph\n",
    "    # We use [-1] because cfgnnexplanier stores information about the cfs in a list\n",
    "    # (one entry per counterfactual edge set).\n",
    "    # Each cf set is of better quality than the previous one.\n",
    "    original_prediction = cf[-1][5]\n",
    "    # just get cfs[-1][11] (which is the #edge-deletions)\n",
    "    perturbations = cf[-1][11]\n",
    "    # store this against the corresponding label in the dictionry\n",
    "    per_label_explanation_size[f\"label-{int(original_prediction)}\"].append(int(perturbations))\n",
    "\n",
    "for label in per_label_explanation_size:\n",
    "    nodes_per_prediction[label] = len(per_label_explanation_size[label])\n",
    "\n",
    "for label in range(NUMBER_OF_LABELS):\n",
    "    # if there was no node in the eval-set with that label\n",
    "    if len(per_label_explanation_size[f\"label-{int(label)}\"]) == 0:\n",
    "        mean, std = None, None\n",
    "    else:\n",
    "        mean = np.mean(per_label_explanation_size[f\"label-{int(label)}\"])\n",
    "        std = np.std(per_label_explanation_size[f\"label-{int(label)}\"])\n",
    "    per_label_explanation_size[f\"label-{int(label)}\"] = [mean, std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-label Explanation size:\n",
      "label-1: 1.50 +- 0.58\n",
      "label-0: 1.00 +- 0.00\n",
      "label-2: 1.05 +- 0.22\n",
      "label-3: 1.75 +- 0.83\n",
      "\n",
      "Nodes per predicted label in the eval-set:\n",
      "defaultdict(<class 'int'>, {'label-1': 29, 'label-3': 17, 'label-2': 30})\n",
      "\n",
      "Nodes per post-perturbation-prediction in the eval-set:\n",
      "defaultdict(<class 'int'>, {'label-1': 22, 'label-0': 2, 'label-2': 20, 'label-3': 4})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Per-label Explanation size:\")\n",
    "for key, value in per_label_explanation_size.items(): # format: label: (mean, std)\n",
    "    print(f\"{key}: {value[0]:.2f} +- {value[1]:.2f}\")\n",
    "print()\n",
    "print(f\"Nodes per predicted label in the eval-set:\\n{NODES_PER_PREDICTED_LABEL_IN_EVAL_SET}\\n\")\n",
    "print(f\"Nodes per post-perturbation-prediction in the eval-set:\\n{nodes_per_prediction}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_size = list()\n",
    "missed = 0\n",
    "# iterate over the cfs\n",
    "for cf in cfs:\n",
    "    # if: cf is []: cf wasn't found, hence skip\n",
    "    if cf == []:\n",
    "        missed += 1\n",
    "        continue\n",
    "    # else: just get cfs[-1][11] (which is the #edge-deletions) in a list\n",
    "    # [-1] because cfgnnexplanier stores information about the cfs in a list\n",
    "    # (one entry per counterfactual edge set).\n",
    "    # Each cf set is of better quality than the previous one.\n",
    "    explanation_size.append(int(cf[-1][11]))\n",
    "# take mean and std\n",
    "explanation_size = [np.mean(explanation_size), np.std(explanation_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation_size:\n",
      "1.31 +- 0.55\n",
      "\n",
      "#Nodes in the eval set: 76\n",
      "#Nodes for which cf wasn't found: 28\n",
      "Hence, #nodes over which size was calculated: 48\n"
     ]
    }
   ],
   "source": [
    "print(\"Explanation_size:\")\n",
    "print(f\"{explanation_size[0]:.2f} +- {explanation_size[1]:.2f}\")\n",
    "print()\n",
    "print(f\"#Nodes in the eval set: {len(eval_set)}\")\n",
    "print(f\"#Nodes for which cf wasn't found: {missed}\")\n",
    "print(f\"Hence, #nodes over which size was calculated: {len(eval_set) - missed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-label Fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_for_which_cf_was_found = [cf[-1][0] for cf in cfs if cf != []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_label_misses = defaultdict(int)\n",
    "\n",
    "# iterate over cfs\n",
    "for node in eval_set:\n",
    "    # get prediction\n",
    "    label = PREDICTIONS[node]\n",
    "    # check if cf was found\n",
    "    if node not in nodes_for_which_cf_was_found:\n",
    "        per_label_misses[f\"label-{label}\"] += 1\n",
    "\n",
    "per_label_fidelity = defaultdict(int)\n",
    "for label in per_label_misses:    \n",
    "    per_label_fidelity[label] = per_label_misses[label]/NODES_PER_PREDICTED_LABEL_IN_EVAL_SET[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'label-2': 0.9333333333333333})\n"
     ]
    }
   ],
   "source": [
    "print(per_label_fidelity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity:\n",
      "0.37\n"
     ]
    }
   ],
   "source": [
    "print(\"Fidelity:\")\n",
    "fidelity = 1 - len(nodes_for_which_cf_was_found)/len(eval_set)\n",
    "print(f\"{fidelity:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "68c408a09fc6b9af4d557fa69fd931fc5c0935ab87f3b3ea2b2f71f9a639c9ba"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('gnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
