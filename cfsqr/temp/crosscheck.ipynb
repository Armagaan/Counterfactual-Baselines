{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross check labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cfgnn bashapes dataset\n",
    "path_cfgnn = \"../cfgnnexplainer/data/gnn_explainer/syn1.pickle\"\n",
    "# path_cfgnn = \"../cfgnnexplainer/data/gnn_explainer/syn4.pickle\"\n",
    "with open(path_cfgnn, \"rb\") as file:\n",
    "    dataset_cfgnn = pickle.load(file) # format: dict(adj, feat, labels, train_idx, test_idx)\n",
    "\n",
    "# get cfsqr bashapes dataset\n",
    "path_cfsqr = \"datasets/BA_Shapes/syn_data.pkl\"\n",
    "# path_cfsqr = \"datasets/Tree_Cycles/syn_data.pkl\"\n",
    "with open(path_cfsqr, \"rb\") as file:\n",
    "    dataset_cfsqr = pickle.load(file)\n",
    "    # format tuple():\n",
    "    '''\n",
    "    [\n",
    "        0. adjacency_matrix\n",
    "        1. features\n",
    "        2. y_train # [0., 1., 0., 0.,] means label 1.\n",
    "        3. y_val\n",
    "        4. y_test\n",
    "        5. train_mask\n",
    "        6. val_mask\n",
    "        7. test_mask\n",
    "        8. e_labels # how are these edge labels decided?\n",
    "    ]\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences: 0\n",
      "Nice, Same graphs!\n"
     ]
    }
   ],
   "source": [
    "# same adjacency matrices?\n",
    "differences = np.sum(dataset_cfgnn['adj'][0] - dataset_cfsqr[0]).astype(int)\n",
    "print(f\"Differences: {differences}\")\n",
    "\n",
    "if differences == 0:\n",
    "    print(\"Nice, Same graphs!\")\n",
    "else:\n",
    "    print(\"Oops!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate node-label mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CFGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_cfgnn = {node:label for node, label in enumerate(dataset_cfgnn['labels'].flatten())}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CFSQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR all datasets\n",
    "labels_matrix_cfsqr = np.bitwise_or(\n",
    "    np.bitwise_or(\n",
    "        dataset_cfsqr[2].astype(int),\n",
    "        dataset_cfsqr[3].astype(int)\n",
    "    ),\n",
    "    dataset_cfsqr[4].astype(int)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_cfsqr = {node:label for node, label in enumerate(np.argmax(labels_matrix_cfsqr, axis=-1))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the adjacency matrices are the same, there is no node which is present in one dataset and absent in the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mismatches: 0\n"
     ]
    }
   ],
   "source": [
    "mismatches = 0\n",
    "for node in labels_cfgnn.keys():\n",
    "    label_cfgnn = labels_cfgnn[node]\n",
    "    label_cfsqr = labels_cfsqr[node]\n",
    "    if label_cfgnn != label_cfsqr:\n",
    "        mismatches += 1\n",
    "        print(f\"CFGNN: {node}:{label_cfgnn}\")\n",
    "        print(f\"CFSQR: {node}:{label_cfsqr}\")\n",
    "print(f\"Mismatches: {mismatches}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CFSQR Black-box accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to running the following cells, ensure that all the cells above are run for the same dataset as you intend to use now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = \"outputs/bashapes/bashapes-alp_0.0-1653544735\"\n",
    "# FOLDER = \"outputs/treecycles/treecycles-alp_0.0-1653386395\"\n",
    "\n",
    "with open(f\"{FOLDER}/pred_label_dict.pkl\", \"rb\") as file:\n",
    "    pred_label_dict = pickle.load(file) # format: node_id: initial_blackbox_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 97.37%\n"
     ]
    }
   ],
   "source": [
    "mismatches = 0\n",
    "for node in pred_label_dict.keys():\n",
    "    if labels_cfsqr[node] != int(pred_label_dict[node]):\n",
    "        mismatches += 1\n",
    "\n",
    "print(f\"Test set accuracy: {100 * (1 - mismatches/len(pred_label_dict.keys())):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7d096456d4adc4d0d94f2f60b5cf993aa1d5a534cad4a79ff1a4d3ab1294b60"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('cfsqr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
